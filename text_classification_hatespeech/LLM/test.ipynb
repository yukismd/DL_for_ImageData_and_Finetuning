{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031411af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad67b4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2ogpte import H2OGPTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d65da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('tmp/h2ogpte_key_hatespeechdetect.txt', 'r')\n",
    "API_KEY = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "621533dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Server version 1.5.0-dev4 doesn't match client version 1.5.0-dev2: unexpected errors may occur.\n",
      "Please install the correct version of H2OGPTE with `pip install h2ogpte==1.5.0-dev4`.\n",
      "You can enable strict version checking by passing strict_version_check=True.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<h2ogpte.h2ogpte.H2OGPTE at 0x105290c40>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = H2OGPTE(\n",
    "    address=\"https://playground.h2ogpte.h2o.ai\",\n",
    "    api_key=API_KEY)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0c7250e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = client.get_llms()\n",
    "len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "745d4c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h2oai/h2ogpt-4096-llama2-70b-chat',\n",
       " 'NousResearch/Nous-Capybara-34B',\n",
       " 'mistralai/Mistral-7B-Instruct-v0.2',\n",
       " 'h2oai/h2o-danube2-1.8b-chat',\n",
       " 'SeaLLMs/SeaLLM-7B-v2.5',\n",
       " 'mistral-small-latest',\n",
       " 'mistral-large-latest',\n",
       " 'mistral-medium',\n",
       " 'claude-3-sonnet-20240229',\n",
       " 'claude-3-opus-20240229',\n",
       " 'claude-3-haiku-20240307',\n",
       " 'gemini-1.5-pro-latest',\n",
       " 'gpt-3.5-turbo-0613',\n",
       " 'gpt-3.5-turbo-16k-0613',\n",
       " 'gpt-35-turbo-1106',\n",
       " 'gpt-4-1106-preview']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m['base_model'] for m in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3555b7fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de38d561-554a-43bc-8a16-28a59bd1f0c5'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_session_id = client.create_chat_session_on_default_collection()\n",
    "chat_session_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09afc01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "MODEL = \"gpt-4-1106-preview\"\n",
    "SYS_PROMPT = \"あなたは日本語で会話を実施するAIです。返答は必ず日本語です。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3552e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h2ogpte.session.Session object at 0x1054b4850>\n",
      "<class 'h2ogpte.session.Session'>\n"
     ]
    }
   ],
   "source": [
    "with client.connect(chat_session_id) as session:\n",
    "    print(session)\n",
    "    print(type(session))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "397981db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは、山田さん。もちろん、お名前は覚えておきます。どういったご用件でしょうか？\n",
      "-----------------\n",
      "私はあなたの名前を知ることができません。あなたが以前にお名前を教えていない限り、私にはわかりません。もし教えていただければ、今後の会話でお名前を使うことができます。\n"
     ]
    }
   ],
   "source": [
    "with client.connect(chat_session_id) as session:\n",
    "    answer = session.query(\n",
    "        message = 'こんにちは、私の名前は山田です。覚えておいて下さい。',\n",
    "        system_prompt=SYS_PROMPT,\n",
    "        llm=MODEL,\n",
    "        rag_config={\"rag_type\": \"llm_only\",},\n",
    "    ).content\n",
    "    print(answer)\n",
    "    \n",
    "    print(\"-----------------\")\n",
    "    \n",
    "    answer = session.query(\n",
    "        message = '私の名前はなんでした？',\n",
    "        system_prompt=SYS_PROMPT,\n",
    "        llm=MODEL,\n",
    "        rag_config={\"rag_type\": \"llm_only\",},\n",
    "    ).content\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "158b9571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "こんにちは、山田さん。もちろん、お名前は覚えておきます。どういったご用件でしょうか？\n",
      "-----------------\n",
      "私はあなたの名前を知ることができません。あなたが以前にお名前を教えていない限り、私にはわかりません。もし教えていただければ、その名前でお呼びすることができます。\n"
     ]
    }
   ],
   "source": [
    "with client.connect(chat_session_id) as session:\n",
    "    answer = session.query(\n",
    "        message = 'こんにちは、私の名前は山田です。覚えておいて下さい。',\n",
    "        system_prompt=SYS_PROMPT,\n",
    "        llm=MODEL,\n",
    "        rag_config={\"rag_type\": \"llm_only\",},\n",
    "    ).content\n",
    "    print(answer)\n",
    "    \n",
    "print(\"-----------------\")\n",
    "\n",
    "with client.connect(chat_session_id) as session2:\n",
    "    answer = session2.query(\n",
    "        message = '私の名前はなんでした？',\n",
    "        system_prompt=SYS_PROMPT,\n",
    "        llm=MODEL,\n",
    "        rag_config={\"rag_type\": \"llm_only\",},\n",
    "    ).content\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0eb09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae027d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Answer(content='こんにちは、山田さん。お会いできて嬉しいです。何かお手伝いできることはありますか？', error='', prompt_raw='こんにちは、私の名前は山田です。', llm='gpt-4-1106-preview', input_tokens=46, output_tokens=37, origin='answer_question_using_context')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = client.answer_question(\n",
    "    llm=MODEL,\n",
    "    question='こんにちは、私の名前は山田です。',\n",
    "    system_prompt=SYS_PROMPT,\n",
    ")\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba0bffb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Konnichiwa, Yamada-san! Ogenki desu ka? (こんにちは、山田さん！お元気ですか？)\\n\\n* Konnichiwa (こんにちは) - Hello\\n* Ogenki desu ka (お元気ですか) - How are you?\\n\\nI'm glad to meet you, Yamada-san! I'm doing well, thanks for asking. How about you?\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc558a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
