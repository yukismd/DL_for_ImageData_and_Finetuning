{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1565e14e",
   "metadata": {},
   "source": [
    "# Text Classification using HuggingFace transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62086e5a",
   "metadata": {},
   "source": [
    "参考：\n",
    "- https://huggingface.co/docs/transformers/ja/training\n",
    "- https://huggingface.co/docs/transformers/tasks/sequence_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f48ef3",
   "metadata": {},
   "source": [
    "利用モデル\n",
    "- https://huggingface.co/line-corporation/line-distilbert-base-japanese\n",
    "- https://huggingface.co/line-corporation/line-distilbert-base-japanese/blob/main/config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ba09e5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n",
      "4.40.1\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "print(datasets.__version__)\n",
    "import transformers\n",
    "print(transformers.__version__)\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1310c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>英語が堪能な知り合いのブログで紹介されていて、この度自分も英語を勉強しに海外へ行くので文法の...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>どっちが先に出たかしりませんが、確かにアントールドな歴史です。興味深い。</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>句動詞の勉強の為に購入しました。以前English Phrasal Verbs in Use...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>値段も少し高めだが、中身は充実していると思う。まずは普通の公式本をしっかり解いてからなのです...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>アマチュア無線を趣味としている者として、世界の最新のトレンドが理解でき大変参考となった。</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>どの章も読みにくく、女性にむけてなのか 男性に向けてなのかわからず結局 男女は違うんだ てこ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>私は6年前くらいに3000円でTSU◯AYAで買いましたよもちろん新品で杖よりお気に入りです</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>沢山の方が高いレビューされているとおり英語を教える人にとっては、日本語の文法教材より理解しやすい.</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>日本語の字幕がないので全く意味がわからない。日本語字幕付きがあれば、すぐにでも注文したいので...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>28日間の感謝のやり方が書かれた本です。the secretの実践本です。まだ途中ですが、か...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  rating  label\n",
       "579  英語が堪能な知り合いのブログで紹介されていて、この度自分も英語を勉強しに海外へ行くので文法の...       5      0\n",
       "633               どっちが先に出たかしりませんが、確かにアントールドな歴史です。興味深い。       4      0\n",
       "49   句動詞の勉強の為に購入しました。以前English Phrasal Verbs in Use...       5      0\n",
       "14   値段も少し高めだが、中身は充実していると思う。まずは普通の公式本をしっかり解いてからなのです...       3      1\n",
       "372       アマチュア無線を趣味としている者として、世界の最新のトレンドが理解でき大変参考となった。       5      0\n",
       "227  どの章も読みにくく、女性にむけてなのか 男性に向けてなのかわからず結局 男女は違うんだ てこ...       1      1\n",
       "189     私は6年前くらいに3000円でTSU◯AYAで買いましたよもちろん新品で杖よりお気に入りです       5      0\n",
       "34   沢山の方が高いレビューされているとおり英語を教える人にとっては、日本語の文法教材より理解しやすい.       5      0\n",
       "311  日本語の字幕がないので全く意味がわからない。日本語字幕付きがあれば、すぐにでも注文したいので...       1      1\n",
       "250  28日間の感謝のやり方が書かれた本です。the secretの実践本です。まだ途中ですが、か...       5      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./tmp/amazon_review_sample1k.csv')\n",
    "print(df.shape)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f56780b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    850\n",
       "1    150\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d359341",
   "metadata": {},
   "source": [
    "-  label=1 : ratingが3以下（Negative）\n",
    "-  label=0 : ratingが4以上（Positive）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7820c639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 3), (200, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=123)\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9df0346",
   "metadata": {},
   "source": [
    "### datasets.Datasetの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2917e17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'rating', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接csvを読み込む場合\n",
    "datasets.load_dataset('csv', data_files=['./tmp/amazon_review_sample1k.csv'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe43aad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 800\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandasから変換\n",
    "dataset_train = datasets.Dataset.from_pandas(df_train[['text','label']], preserve_index=False)\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb4483c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0497c00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'全編英語だけど絵が多いので英語苦手な人でも作れると思いますが、もちろん\\x08細かく細かく全てのステップの図解が載っている訳ではないので自己責任でご購入を検討してくださいませ。すごく沢山の種類が載っておりかなり楽しめました。一生のバイブルになるでしょう。'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ec4b5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05824f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test = datasets.Dataset.from_pandas(df_test[['text','label']], preserve_index=False)\n",
    "dataset_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12589163",
   "metadata": {},
   "source": [
    "### Tokenizerの適用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5fd43c",
   "metadata": {},
   "source": [
    "Tokenizerに関して: https://huggingface.co/docs/transformers/ja/tokenizer_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bd25b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fugashi sentencepiece　unidic-lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "0b3a17b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertJapaneseTokenizer(name_or_path='line-corporation/line-distilbert-base-japanese', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '<unk>', 'sep_token': '[SEP]', 'pad_token': '<pad>', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('line-corporation/line-distilbert-base-japanese')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "236f993f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.bert_japanese.tokenization_bert_japanese.BertJapaneseTokenizer"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6918e9a5",
   "metadata": {},
   "source": [
    "https://huggingface.co/transformers/v4.11.3/_modules/transformers/models/bert_japanese/tokenization_bert_japanese.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "de577874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('全編英語だけど絵が多いので英語苦手な人でも作れると思いますが、もちろん\\x08細かく細かく全てのステップの図解が載っている訳ではないので自己責任でご購入を検討してくださいませ。すごく沢山の種類が載っておりかなり楽しめました。一生のバイブルになるでしょう。',\n",
       " 0)"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train['text'][0], dataset_train['label'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "4a691d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 180, 10807, 1685, 47, 524, 1749, 14, 621, 5, 9, 1685, 5231, 16, 54, 9, 20, 124, 368, 15, 318, 39, 14, 6, 1784, 10234, 13016, 10143, 10143, 1363, 5, 4487, 5, 788, 10611, 14, 10039, 12, 42, 3031, 9, 10, 50, 5, 9, 2593, 2767, 9, 162, 949, 13, 2678, 17, 12, 525, 231, 8, 3947, 5442, 5, 1551, 14, 10039, 12, 282, 1546, 7365, 70, 11, 8, 6202, 5, 2191, 774, 7, 136, 502, 8, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(dataset_train['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "7249814b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 578,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer(dataset_train['text'][0])['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "0644cb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'全編 英語 だ けど 絵 が 多い の で 英語 苦手 な 人 で も 作れる と 思い ます が 、 もちろん \\x08 細かく 細かく 全て の ステップ の 図解 が 載っ て いる 訳 で は ない の で 自己 責任 で ご 購入 を 検討 し て ください ませ 。 すごく 沢山 の 種類 が 載っ て おり かなり 楽しめ まし た 。 一生 の バイブル に なる でしょう 。'"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(\n",
    "    tokenizer(dataset_train['text'][0])['input_ids']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "33ac0d2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁全',\n",
       " '編',\n",
       " '▁英語',\n",
       " '▁だ',\n",
       " '▁けど',\n",
       " '▁絵',\n",
       " '▁が',\n",
       " '▁多い',\n",
       " '▁の',\n",
       " '▁で',\n",
       " '▁英語',\n",
       " '▁苦手',\n",
       " '▁な',\n",
       " '▁人',\n",
       " '▁で',\n",
       " '▁も',\n",
       " '▁作',\n",
       " 'れる',\n",
       " '▁と',\n",
       " '▁思い',\n",
       " '▁ます',\n",
       " '▁が',\n",
       " '▁、',\n",
       " '▁もちろん',\n",
       " '▁',\n",
       " '\\x08',\n",
       " '▁細かく',\n",
       " '▁細かく',\n",
       " '▁全て',\n",
       " '▁の',\n",
       " '▁ステップ',\n",
       " '▁の',\n",
       " '▁図',\n",
       " '解',\n",
       " '▁が',\n",
       " '▁載っ',\n",
       " '▁て',\n",
       " '▁いる',\n",
       " '▁訳',\n",
       " '▁で',\n",
       " '▁は',\n",
       " '▁ない',\n",
       " '▁の',\n",
       " '▁で',\n",
       " '▁自己',\n",
       " '▁責任',\n",
       " '▁で',\n",
       " '▁ご',\n",
       " '▁購入',\n",
       " '▁を',\n",
       " '▁検討',\n",
       " '▁し',\n",
       " '▁て',\n",
       " '▁ください',\n",
       " '▁ませ',\n",
       " '▁。',\n",
       " '▁すごく',\n",
       " '▁沢山',\n",
       " '▁の',\n",
       " '▁種類',\n",
       " '▁が',\n",
       " '▁載っ',\n",
       " '▁て',\n",
       " '▁おり',\n",
       " '▁かなり',\n",
       " '▁楽しめ',\n",
       " '▁まし',\n",
       " '▁た',\n",
       " '▁。',\n",
       " '▁一生',\n",
       " '▁の',\n",
       " '▁バイ',\n",
       " 'ブル',\n",
       " '▁に',\n",
       " '▁なる',\n",
       " '▁でしょう',\n",
       " '▁。']"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# トークン化\n",
    "tokenizer.tokenize(dataset_train['text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "e0afef9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.tokenize(dataset_train['text'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "83ca7615",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[180,\n",
       " 10807,\n",
       " 1685,\n",
       " 47,\n",
       " 524,\n",
       " 1749,\n",
       " 14,\n",
       " 621,\n",
       " 5,\n",
       " 9,\n",
       " 1685,\n",
       " 5231,\n",
       " 16,\n",
       " 54,\n",
       " 9,\n",
       " 20,\n",
       " 124,\n",
       " 368,\n",
       " 15,\n",
       " 318,\n",
       " 39,\n",
       " 14,\n",
       " 6,\n",
       " 1784,\n",
       " 10234,\n",
       " 13016,\n",
       " 10143,\n",
       " 10143,\n",
       " 1363,\n",
       " 5,\n",
       " 4487,\n",
       " 5,\n",
       " 788,\n",
       " 10611,\n",
       " 14,\n",
       " 10039,\n",
       " 12,\n",
       " 42,\n",
       " 3031,\n",
       " 9,\n",
       " 10,\n",
       " 50,\n",
       " 5,\n",
       " 9,\n",
       " 2593,\n",
       " 2767,\n",
       " 9,\n",
       " 162,\n",
       " 949,\n",
       " 13,\n",
       " 2678,\n",
       " 17,\n",
       " 12,\n",
       " 525,\n",
       " 231,\n",
       " 8,\n",
       " 3947,\n",
       " 5442,\n",
       " 5,\n",
       " 1551,\n",
       " 14,\n",
       " 10039,\n",
       " 12,\n",
       " 282,\n",
       " 1546,\n",
       " 7365,\n",
       " 70,\n",
       " 11,\n",
       " 8,\n",
       " 6202,\n",
       " 5,\n",
       " 2191,\n",
       " 774,\n",
       " 7,\n",
       " 136,\n",
       " 502,\n",
       " 8]"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# トークンのID変換\n",
    "tokenizer.convert_tokens_to_ids(\n",
    "    tokenizer.tokenize(dataset_train['text'][0])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "dde5527d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 180, 10807, 1685, 47, 524, 1749, 14, 621, 5, 9, 1685, 5231, 16, 54, 9, 20, 124, 368, 15, 318, 39, 14, 6, 1784, 10234, 13016, 10143, 10143, 1363, 5, 4487, 5, 788, 10611, 14, 10039, 12, 42, 3031, 9, 10, 50, 5, 9, 2593, 2767, 9, 162, 949, 13, 2678, 17, 12, 525, 231, 8, 3947, 5442, 5, 1551, 14, 10039, 12, 282, 1546, 7365, 70, 11, 8, 6202, 5, 2191, 774, 7, 136, 502, 8, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 特殊トークンの付与\n",
    "tokenizer.prepare_for_model(\n",
    "    tokenizer.convert_tokens_to_ids(\n",
    "        tokenizer.tokenize(dataset_train['text'][0])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009d3eaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "32ff32fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    #return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "    return tokenizer(examples[\"text\"], truncation=True, max_length=512)   # max_length=512はモデルのmax_position_embeddings\n",
    "\n",
    "# truncation=True -> max_lengthの長さに切り詰め"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6868e09",
   "metadata": {},
   "source": [
    "Padding, Truncationに関して: https://huggingface.co/docs/transformers/ja/pad_truncation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "6bfb2607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea390d89d0184dc8bdcb996f416680ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 800\n",
       "})"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets_train = dataset_train.map(tokenize_function, batched=True)\n",
    "tokenized_datasets_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "fc64f9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c0a24a1db374783936121b2fecbf926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets_test = dataset_test.map(tokenize_function, batched=True)\n",
    "tokenized_datasets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "189c19b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_datasets_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "c32ec5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 3))\n",
    "pd.Series([len(i) for i in tokenized_datasets_train['input_ids']]).hist(bins=30)\n",
    "plt.title('Distribution of Token Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "ff416540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# textカラムの削除\n",
    "tokenized_datasets_train = tokenized_datasets_train.remove_columns(['text'])\n",
    "tokenized_datasets_test = tokenized_datasets_test.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "c3b493fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_type_idsカラムの削除\n",
    "tokenized_datasets_train = tokenized_datasets_train.remove_columns(['token_type_ids'])\n",
    "tokenized_datasets_test = tokenized_datasets_test.remove_columns(['token_type_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564a8515",
   "metadata": {},
   "source": [
    "DistilBERT doesn’t have token_type_ids: https://huggingface.co/docs/transformers/model_doc/distilbert#usage-tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "8bf79dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelカラムをlabelsへリネーム\n",
    "tokenized_datasets_train = tokenized_datasets_train.rename_column('label', 'labels')\n",
    "tokenized_datasets_test = tokenized_datasets_test.rename_column('label', 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "ed29f3a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 800\n",
       "})"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "82183886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 200\n",
       "})"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "e6cae770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor型に変換\n",
    "tokenized_datasets_train.set_format(\"torch\")\n",
    "tokenized_datasets_test.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "0715c9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor(0),\n",
       " 'input_ids': tensor([    2,   180, 10807,  1685,    47,   524,  1749,    14,   621,     5,\n",
       "             9,  1685,  5231,    16,    54,     9,    20,   124,   368,    15,\n",
       "           318,    39,    14,     6,  1784, 10234, 13016, 10143, 10143,  1363,\n",
       "             5,  4487,     5,   788, 10611,    14, 10039,    12,    42,  3031,\n",
       "             9,    10,    50,     5,     9,  2593,  2767,     9,   162,   949,\n",
       "            13,  2678,    17,    12,   525,   231,     8,  3947,  5442,     5,\n",
       "          1551,    14, 10039,    12,   282,  1546,  7365,    70,    11,     8,\n",
       "          6202,     5,  2191,   774,     7,   136,   502,     8,     3]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1])}"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "5075f2fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 598,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_datasets_train[0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff245b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90e207c3",
   "metadata": {},
   "source": [
    "### Dataloder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "14fdb79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertJapaneseTokenizer(name_or_path='line-corporation/line-distilbert-base-japanese', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '<unk>', 'sep_token': '[SEP]', 'pad_token': '<pad>', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 599,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "3b8059aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "#data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"longest\", max_length=512)\n",
    "#data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=\"max_length\", max_length=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9789e3c",
   "metadata": {},
   "source": [
    "Collator: https://huggingface.co/docs/transformers/ja/main_classes/data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "a0ebe4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(tokenized_datasets_train, shuffle=True, batch_size=batch_size, collate_fn=data_collator)\n",
    "eval_dataloader = DataLoader(tokenized_datasets_test, batch_size=batch_size, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "1d2114fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f89a8b73c10>"
      ]
     },
     "execution_count": 602,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "e60ae168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorWithPadding(tokenizer=BertJapaneseTokenizer(name_or_path='line-corporation/line-distilbert-base-japanese', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '<unk>', 'sep_token': '[SEP]', 'pad_token': '<pad>', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}, padding=True, max_length=None, pad_to_multiple_of=None, return_tensors='pt')"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "870446d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 25)"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader), len(eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "18ff9b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100.0, 25.0)"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "800/batch_size, 200/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1071b1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07d41931",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "4ee141ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at line-corporation/line-distilbert-base-japanese and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('line-corporation/line-distilbert-base-japanese', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "dd75e553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b44551",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/v4.14.1/model_doc/distilbert#transformers.DistilBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "9b80142f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(32768, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "98412d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"_name_or_path\": \"line-corporation/line-distilbert-base-japanese\",\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": true,\n",
       "  \"tie_weights_\": true,\n",
       "  \"transformers_version\": \"4.40.1\",\n",
       "  \"vocab_size\": 32768\n",
       "}"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "79f83cbb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model check\n",
    "# (batch size, token length)\n",
    "sample_out = model(\n",
    "    input_ids=torch.zeros((4, 15), dtype=torch.int),\n",
    "    attention_mask=torch.zeros((4, 15), dtype=torch.int)\n",
    ")\n",
    "#sample_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "ac73bcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "1e597ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1605, 0.2709],\n",
       "        [0.1605, 0.2709],\n",
       "        [0.1605, 0.2709],\n",
       "        [0.1605, 0.2709]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 612,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "00745753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1605, 0.2709],\n",
       "        [0.1605, 0.2709],\n",
       "        [0.1605, 0.2709],\n",
       "        [0.1605, 0.2709]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logitでのアウトプット\n",
    "sample_out.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "d0bb6d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1])"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max index\n",
    "torch.argmax(sample_out.logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "141474da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_out.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "4fa5d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_out[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "67bb1a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_out.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "e099e9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_out.hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "d0a55bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 15, 768]) tensor(-0.0163, grad_fn=<MeanBackward0>) tensor(0.7592, grad_fn=<StdBackward0>)\n",
      "torch.Size([4, 15, 768]) tensor(-0.0044, grad_fn=<MeanBackward0>) tensor(0.5720, grad_fn=<StdBackward0>)\n",
      "torch.Size([4, 15, 768]) tensor(-0.0038, grad_fn=<MeanBackward0>) tensor(0.7768, grad_fn=<StdBackward0>)\n",
      "torch.Size([4, 15, 768]) tensor(-0.0017, grad_fn=<MeanBackward0>) tensor(0.7886, grad_fn=<StdBackward0>)\n",
      "torch.Size([4, 15, 768]) tensor(0.0037, grad_fn=<MeanBackward0>) tensor(0.8767, grad_fn=<StdBackward0>)\n",
      "torch.Size([4, 15, 768]) tensor(0.0016, grad_fn=<MeanBackward0>) tensor(0.8713, grad_fn=<StdBackward0>)\n",
      "torch.Size([4, 15, 768]) tensor(-0.0112, grad_fn=<MeanBackward0>) tensor(0.8957, grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sample_out.hidden_states)):\n",
    "    print(sample_out.hidden_states[i].shape, sample_out[1][i].mean(), sample_out[1][i].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af68186f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b8f79e0",
   "metadata": {},
   "source": [
    "### Optimizer, Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "39ee09d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7f8a8a4f86d0>"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "91124bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 5e-05\n",
       "    maximize: False\n",
       "    weight_decay: 0.01\n",
       ")"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "84fb60b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.optim.lr_scheduler.LambdaLR at 0x7f89a8b5f4c0>"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "print(len(train_dataloader), num_training_steps)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e6712c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca8eab66",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "9d9b9a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "5076488b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f89a8b73c10>"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "8fbdcd44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1343abf5654f9eb6b65085cadea012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 233])\n",
      "attention_mask shape:  torch.Size([8, 233])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 143])\n",
      "attention_mask shape:  torch.Size([8, 143])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 426])\n",
      "attention_mask shape:  torch.Size([8, 426])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 134])\n",
      "attention_mask shape:  torch.Size([8, 134])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 134])\n",
      "attention_mask shape:  torch.Size([8, 134])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 191])\n",
      "attention_mask shape:  torch.Size([8, 191])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 224])\n",
      "attention_mask shape:  torch.Size([8, 224])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 183])\n",
      "attention_mask shape:  torch.Size([8, 183])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 262])\n",
      "attention_mask shape:  torch.Size([8, 262])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 338])\n",
      "attention_mask shape:  torch.Size([8, 338])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 145])\n",
      "attention_mask shape:  torch.Size([8, 145])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 195])\n",
      "attention_mask shape:  torch.Size([8, 195])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 152])\n",
      "attention_mask shape:  torch.Size([8, 152])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 262])\n",
      "attention_mask shape:  torch.Size([8, 262])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 325])\n",
      "attention_mask shape:  torch.Size([8, 325])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 246])\n",
      "attention_mask shape:  torch.Size([8, 246])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 238])\n",
      "attention_mask shape:  torch.Size([8, 238])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 175])\n",
      "attention_mask shape:  torch.Size([8, 175])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 165])\n",
      "attention_mask shape:  torch.Size([8, 165])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 269])\n",
      "attention_mask shape:  torch.Size([8, 269])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 299])\n",
      "attention_mask shape:  torch.Size([8, 299])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 161])\n",
      "attention_mask shape:  torch.Size([8, 161])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 363])\n",
      "attention_mask shape:  torch.Size([8, 363])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 395])\n",
      "attention_mask shape:  torch.Size([8, 395])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 286])\n",
      "attention_mask shape:  torch.Size([8, 286])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 168])\n",
      "attention_mask shape:  torch.Size([8, 168])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 168])\n",
      "attention_mask shape:  torch.Size([8, 168])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 455])\n",
      "attention_mask shape:  torch.Size([8, 455])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 178])\n",
      "attention_mask shape:  torch.Size([8, 178])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 445])\n",
      "attention_mask shape:  torch.Size([8, 445])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 155])\n",
      "attention_mask shape:  torch.Size([8, 155])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 222])\n",
      "attention_mask shape:  torch.Size([8, 222])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 187])\n",
      "attention_mask shape:  torch.Size([8, 187])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 355])\n",
      "attention_mask shape:  torch.Size([8, 355])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 202])\n",
      "attention_mask shape:  torch.Size([8, 202])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 284])\n",
      "attention_mask shape:  torch.Size([8, 284])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 273])\n",
      "attention_mask shape:  torch.Size([8, 273])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 311])\n",
      "attention_mask shape:  torch.Size([8, 311])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 131])\n",
      "attention_mask shape:  torch.Size([8, 131])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 442])\n",
      "attention_mask shape:  torch.Size([8, 442])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 341])\n",
      "attention_mask shape:  torch.Size([8, 341])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 199])\n",
      "attention_mask shape:  torch.Size([8, 199])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 299])\n",
      "attention_mask shape:  torch.Size([8, 299])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 158])\n",
      "attention_mask shape:  torch.Size([8, 158])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 169])\n",
      "attention_mask shape:  torch.Size([8, 169])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 196])\n",
      "attention_mask shape:  torch.Size([8, 196])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 452])\n",
      "attention_mask shape:  torch.Size([8, 452])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 315])\n",
      "attention_mask shape:  torch.Size([8, 315])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 132])\n",
      "attention_mask shape:  torch.Size([8, 132])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 388])\n",
      "attention_mask shape:  torch.Size([8, 388])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 379])\n",
      "attention_mask shape:  torch.Size([8, 379])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 284])\n",
      "attention_mask shape:  torch.Size([8, 284])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 88])\n",
      "attention_mask shape:  torch.Size([8, 88])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 96])\n",
      "attention_mask shape:  torch.Size([8, 96])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 83])\n",
      "attention_mask shape:  torch.Size([8, 83])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 312])\n",
      "attention_mask shape:  torch.Size([8, 312])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 459])\n",
      "attention_mask shape:  torch.Size([8, 459])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 101])\n",
      "attention_mask shape:  torch.Size([8, 101])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 133])\n",
      "attention_mask shape:  torch.Size([8, 133])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 350])\n",
      "attention_mask shape:  torch.Size([8, 350])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 244])\n",
      "attention_mask shape:  torch.Size([8, 244])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 121])\n",
      "attention_mask shape:  torch.Size([8, 121])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 320])\n",
      "attention_mask shape:  torch.Size([8, 320])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 155])\n",
      "attention_mask shape:  torch.Size([8, 155])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 388])\n",
      "attention_mask shape:  torch.Size([8, 388])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 137])\n",
      "attention_mask shape:  torch.Size([8, 137])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 217])\n",
      "attention_mask shape:  torch.Size([8, 217])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 131])\n",
      "attention_mask shape:  torch.Size([8, 131])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 260])\n",
      "attention_mask shape:  torch.Size([8, 260])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 474])\n",
      "attention_mask shape:  torch.Size([8, 474])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 467])\n",
      "attention_mask shape:  torch.Size([8, 467])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 192])\n",
      "attention_mask shape:  torch.Size([8, 192])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 85])\n",
      "attention_mask shape:  torch.Size([8, 85])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 394])\n",
      "attention_mask shape:  torch.Size([8, 394])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 137])\n",
      "attention_mask shape:  torch.Size([8, 137])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 104])\n",
      "attention_mask shape:  torch.Size([8, 104])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 295])\n",
      "attention_mask shape:  torch.Size([8, 295])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 387])\n",
      "attention_mask shape:  torch.Size([8, 387])\n",
      "Epoch: 2/2\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 344])\n",
      "attention_mask shape:  torch.Size([8, 344])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 182])\n",
      "attention_mask shape:  torch.Size([8, 182])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 202])\n",
      "attention_mask shape:  torch.Size([8, 202])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 395])\n",
      "attention_mask shape:  torch.Size([8, 395])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 477])\n",
      "attention_mask shape:  torch.Size([8, 477])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 512])\n",
      "attention_mask shape:  torch.Size([8, 512])\n",
      "dict_keys(['labels', 'input_ids', 'attention_mask'])\n",
      "input_ids shape:  torch.Size([8, 474])\n",
      "attention_mask shape:  torch.Size([8, 474])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [625], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#print(batch)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:994\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    992\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 994\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistilbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:814\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    812\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(input_shape, device\u001b[38;5;241m=\u001b[39mdevice)  \u001b[38;5;66;03m# (bs, seq_length)\u001b[39;00m\n\u001b[0;32m--> 814\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    821\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:575\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    567\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    568\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    569\u001b[0m         hidden_state,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    572\u001b[0m         output_attentions,\n\u001b[1;32m    573\u001b[0m     )\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 575\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:501\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;124;03m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;124;03m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# Self-Attention\u001b[39;00m\n\u001b[0;32m--> 501\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[1;32m    510\u001b[0m     sa_output, sa_weights \u001b[38;5;241m=\u001b[39m sa_output  \u001b[38;5;66;03m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/transformers/models/distilbert/modeling_distilbert.py:227\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(bs, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads \u001b[38;5;241m*\u001b[39m dim_per_head)\n\u001b[1;32m    226\u001b[0m q \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_lin(query))  \u001b[38;5;66;03m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m k \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk_lin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    228\u001b[0m v \u001b[38;5;241m=\u001b[39m shape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_lin(value))  \u001b[38;5;66;03m# (bs, n_heads, k_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    230\u001b[0m q \u001b[38;5;241m=\u001b[39m q \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(dim_per_head)  \u001b[38;5;66;03m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}')\n",
    "    for batch in train_dataloader:\n",
    "        #print(batch.keys())\n",
    "        #print(\"input_ids shape: \", batch['input_ids'].shape)\n",
    "        #print(\"attention_mask shape: \", batch['attention_mask'].shape)\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093a6883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc652f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
